{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# to use a specific GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mgtbench import AutoDetector, AutoExperiment\n",
    "from mgtbench.loading.dataloader import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "supported LLMs and detect categories:\n",
    "\n",
    "categories = ['Physics', 'Medicine', 'Biology', 'Electrical_engineering', 'Computer_science', 'Literature', 'History', 'Education', 'Art', 'Law', 'Management', 'Philosophy', 'Economy', 'Math', 'Statistics', 'Chemistry']\n",
    "\n",
    "llms = ['Moonshot', 'gpt35', 'Mixtral', 'Llama3', 'gpt-4omini']\n",
    "'''\n",
    "data_name = 'AITextDetect'\n",
    "detectLLM = 'Llama3'\n",
    "category = 'Art'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading human data\n",
      "loading machine data\n",
      "data loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing data: 100%|██████████| 8394/8394 [00:00<00:00, 16180.37it/s]\n"
     ]
    }
   ],
   "source": [
    "data = load(data_name, detectLLM, category)\n",
    "# for demo\n",
    "size = 50\n",
    "data['train']['text'] = data['train']['text'][:size]\n",
    "data['train']['label'] = data['train']['label'][:size]\n",
    "data['test']['text'] = data['test']['text'][:size]\n",
    "data['test']['label'] = data['test']['label'][:size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model-based Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at /data1/models/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length is set to 512\n"
     ]
    }
   ],
   "source": [
    "# local path to the model, or model name on huggingface\n",
    "model_name_or_path = '/data1/models/distilbert-base-uncased'\n",
    "metric = AutoDetector.from_detector_name('LM-D', \n",
    "                                            model_name_or_path=model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhiyuan/miniconda3/envs/mgtbench2/lib/python3.11/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate result for each data point\n",
      "Running prediction of detector LM-D\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune finished\n",
      "Predict training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 170.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict testing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 180.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run classification for results\n",
      "==========\n",
      "train: Metric(acc=0.6, precision=0.7142857142857143, recall=0.21739130434782608, f1=0.3333333333333333, auc=0.698268921095008, conf_m=None)\n",
      "test: Metric(acc=0.58, precision=0.6470588235294118, recall=0.23404255319148937, f1=0.34375, auc=0.6967081493376154, conf_m=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = AutoExperiment.from_experiment_name('supervised',detector=[metric])\n",
    "experiment.load_data(data)\n",
    "config = {'need_finetune': True,\n",
    "          'need_save': False,\n",
    "          'epochs': 1, # for model-based detectors\n",
    "          }\n",
    "res = experiment.launch(**config)\n",
    "\n",
    "print('==========')\n",
    "print('train:', res[0].train)\n",
    "print('test:', res[0].test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric-based Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log-likelihood detector\n",
    "model_name_or_path = '/data1/zzy/gpt2-medium'\n",
    "metric = AutoDetector.from_detector_name('ll',\n",
    "                                         model_name_or_path=model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate result for each data point\n",
      "Running prediction of detector ll\n",
      "Predict training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:00<00:03, 24.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 56.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict testing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 63.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run classification for results\n",
      "==========\n",
      "train: Metric(acc=0.85, precision=0.8780487804878049, recall=0.782608695652174, f1=0.8275862068965517, auc=0.8945249597423511, conf_m=None)\n",
      "test: Metric(acc=0.85, precision=0.8076923076923077, recall=0.8936170212765957, f1=0.8484848484848485, auc=0.9359694901645925, conf_m=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = AutoExperiment.from_experiment_name('threshold',detector=[metric])\n",
    "experiment.load_data(data)\n",
    "res = experiment.launch()\n",
    "\n",
    "print('==========')\n",
    "print('train:', res[0].train)\n",
    "print('test:', res[0].test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fast-DetectGPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /data_sda/zhiyuan/models/gpt-j-6B were not used when initializing GPTJForCausalLM: ['transformer.h.0.attn.bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.10.attn.bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.11.attn.bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.12.attn.bias', 'transformer.h.12.attn.masked_bias', 'transformer.h.13.attn.bias', 'transformer.h.13.attn.masked_bias', 'transformer.h.14.attn.bias', 'transformer.h.14.attn.masked_bias', 'transformer.h.15.attn.bias', 'transformer.h.15.attn.masked_bias', 'transformer.h.16.attn.bias', 'transformer.h.16.attn.masked_bias', 'transformer.h.17.attn.bias', 'transformer.h.17.attn.masked_bias', 'transformer.h.18.attn.bias', 'transformer.h.18.attn.masked_bias', 'transformer.h.19.attn.bias', 'transformer.h.19.attn.masked_bias', 'transformer.h.2.attn.bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.20.attn.bias', 'transformer.h.20.attn.masked_bias', 'transformer.h.21.attn.bias', 'transformer.h.21.attn.masked_bias', 'transformer.h.22.attn.bias', 'transformer.h.22.attn.masked_bias', 'transformer.h.23.attn.bias', 'transformer.h.23.attn.masked_bias', 'transformer.h.24.attn.bias', 'transformer.h.24.attn.masked_bias', 'transformer.h.25.attn.bias', 'transformer.h.25.attn.masked_bias', 'transformer.h.26.attn.bias', 'transformer.h.26.attn.masked_bias', 'transformer.h.27.attn.bias', 'transformer.h.27.attn.masked_bias', 'transformer.h.3.attn.bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.8.attn.bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.bias', 'transformer.h.9.attn.masked_bias']\n",
      "- This IS expected if you are initializing GPTJForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPTJForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "scoring_model_name_or_path = '/data_sda/zhiyuan/models/gpt-neo-2.7B'\n",
    "reference_model_name_or_path = '/data_sda/zhiyuan/models/gpt-j-6B'\n",
    "fastDetectGPT = AutoDetector.from_detector_name('fast-detectGPT', \n",
    "                                            scoring_model_name_or_path=scoring_model_name_or_path,\n",
    "                                            reference_model_name_or_path= reference_model_name_or_path\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate result for each data point\n",
      "Running prediction of detector fast-detectGPT\n",
      "Predict training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting: 100%|██████████| 50/50 [00:11<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict testing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting: 100%|██████████| 50/50 [00:13<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run classification for results\n",
      "Finding best threshold for f1 score...\n",
      "==========\n",
      "train: Metric(acc=0.82, precision=0.8214285714285714, recall=0.8518518518518519, f1=0.8363636363636363, auc=0.8631239935587762, conf_m=None)\n",
      "test: Metric(acc=0.9, precision=0.8666666666666667, recall=0.9629629629629629, f1=0.9122807017543859, auc=0.9355877616747181, conf_m=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = AutoExperiment.from_experiment_name('perturb', detector=[fastDetectGPT])\n",
    "experiment.load_data(data)\n",
    "res = experiment.launch()\n",
    "\n",
    "print('==========')\n",
    "print('train:', res[0].train)\n",
    "print('test:', res[0].test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binocolars Detector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data_sda/zhiyuan/models/falcon-7b /data_sda/zhiyuan/models/falcon-7b-instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a6a538519f49bab3a3908a330be5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf3086a62074a2dae95b5dc5b209261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "observer_model_name_or_path = '/data_sda/zhiyuan/models/falcon-7b'\n",
    "performer_model_name_or_path = '/data_sda/zhiyuan/models/falcon-7b-instruct'\n",
    "\n",
    "binoculars = AutoDetector.from_detector_name('Binoculars', \n",
    "                                            observer_model_name_or_path=observer_model_name_or_path,\n",
    "                                            performer_model_name_or_path= performer_model_name_or_path,\n",
    "                                            max_length=1024,\n",
    "                                            mode='low-fpr', # accuracy (f1) or low-fpr\n",
    "                                            # 'default' or 'new', default is the threshold used in the paper, 'new' is the threshold calculated on the new training set\n",
    "                                            threshold='new' \n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate result for each data point\n",
      "Running prediction of detector Binoculars\n",
      "Predict training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting: 100%|██████████| 50/50 [00:14<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict testing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting: 100%|██████████| 50/50 [00:16<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run classification for results\n",
      "Finding best threshold for low-fpr...\n",
      "==========\n",
      "train: Metric(acc=0.54, precision=0.54, recall=1.0, f1=0.7012987012987013, auc=0.9500805152979066, conf_m=None)\n",
      "test: Metric(acc=0.54, precision=0.54, recall=1.0, f1=0.7012987012987013, auc=0.9420289855072463, conf_m=None)\n",
      "Calculate result for each data point\n",
      "Running prediction of detector Binoculars\n",
      "Predict training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting: 100%|██████████| 50/50 [00:14<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict testing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting: 100%|██████████| 50/50 [00:16<00:00,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run classification for results\n",
      "Finding best threshold for accuracy...\n",
      "==========\n",
      "train: Metric(acc=0.9, precision=0.9230769230769231, recall=0.8888888888888888, f1=0.9056603773584906, auc=0.9500805152979066, conf_m=None)\n",
      "test: Metric(acc=0.84, precision=0.8518518518518519, recall=0.8518518518518519, f1=0.8518518518518519, auc=0.9420289855072463, conf_m=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# threshold set for low-fpr\n",
    "binoculars.change_mode('low-fpr')\n",
    "experiment = AutoExperiment.from_experiment_name('threshold', detector=[binoculars])\n",
    "experiment.load_data(data)\n",
    "res = experiment.launch()\n",
    "print('==========')\n",
    "print('train:', res[0].train)\n",
    "print('test:', res[0].test)\n",
    "\n",
    "# threshold set for f1\n",
    "binoculars.change_mode('accuracy')\n",
    "experiment = AutoExperiment.from_experiment_name('threshold', detector=[binoculars])\n",
    "experiment.load_data(data)\n",
    "res = experiment.launch()\n",
    "print('==========')\n",
    "print('train:', res[0].train)\n",
    "print('test:', res[0].test)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
